{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TKO_7092 Evaluation of Machine Learning Methods 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Student name: Saara Mäkelä\n",
    "\n",
    "Student number: 2203834\n",
    "\n",
    "Student email: sahanm@utu.fi\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "Complete the tasks given to you in the letter below. In your submission, explain clearly, precisely, and comprehensively why the cross-validation described in the letter failed, what is the correct way to perform cross-validation in the given scenario, and why the correct cross-validation method will give a reliable estimate of the generalisation performance. Then implement the correct cross-validation for the scenario and report its results.\n",
    "\n",
    "Remember to follow all the general exercise guidelines that are stated in Moodle. Full points (2p) will be given for a submission that demonstrates a deep understanding of cross-validation on pair-input data and implements the requested cross-validation correctly (incl. reporting the results). Partial points (1p) will be given if there are small error(s) but the overall approach is correct. No points will be given if there are significant error(s).\n",
    "\n",
    "The deadline of this exercise is **Wednesday 19 February 2025 at 11:59 PM**. Please contact Juho Heimonen (juaheim@utu.fi) if you have any questions about this exercise.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dear Data Scientist,\n",
    "\n",
    "I have a long-term research project regarding a specific set of proteins. I am attempting to discover small organic compounds that can bind strongly to these proteins and thus act as drugs. I have already made laboratory experiments to measure the affinities between some proteins and drug molecules.\n",
    "\n",
    "My colleague is working on another set of proteins, and the objectives of his project are similar to mine. He has recently discovered thousands of new potential drug molecules. He asked me if I could find the pairs that have the strongest affinities among his proteins and drug molecules. Obviously I do not have the resources to measure all the possible pairs in my laboratory, so I need to prioritise. I decided to do this with the help of machine learning, but I have encountered a problem.\n",
    "\n",
    "Here is what I have done so far: First I trained a K-nearest neighbours regressor with the parameter value K=10 using all the 400 measurements I had already made in the laboratory with my proteins and drug molecules. They comprise of 77 target proteins and 59 drug molecules. Then I performed a leave-one-out cross-validation with this same data to estimate the generalisation performance of the model. I used C-index and got a stellar score above 90%. Finally I used the model to predict the affinities of my colleague's proteins and drug molecules. The problem is: when I selected the highest predicted affinities and tried to verify them in the lab, I found that many of them are much lower in reality. My model clearly does not work despite the high cross-validation score.\n",
    "\n",
    "Please explain why my estimation failed and how leave-one-out cross-validation should be performed to get a reliable estimate. Also, implement the correct leave-one-out cross-validation and report its results. I need to know whether it would be a waste of my resources if I were to use my model any further.\n",
    "\n",
    "The data I used to create my model is available in the files `input.data`, `output.data` and `pairs.data` for you to use. The first file contains the features of the pairs, whereas the second contains their affinities. The third file contains the identifiers of the drug and target molecules of which the pairs are composed. The files are paired, i.e. the i<sup>*th*</sup> row in each file is about the same pair.\n",
    "\n",
    "Looking forward to hearing from you soon.\n",
    "\n",
    "Yours sincerely, \\\n",
    "Bio Scientist\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer the questions about cross-validation on pair-input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why did the estimation described in the letter fail?\n",
    "# How should leave-one-out cross-validation be performed in the given scenario and why?\n",
    "# Remember to provide comprehensive and precise arguments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__<font>Why did the estimation described in the letter fail? </font>__\n",
    "\n",
    "The estimation failed because it didn't take into consideration that it was done to pairs. The scientist made a normal cross-validation and assumed that the test set is independent of the training set, which is not the case with pair-input data. The normal cross-validation doesn't take into consideration the different out-of-sample observation types. It needs to be modified to match the dependencies of different types. Depending on the type of the out-of-sample, observations that share the first or second pair member with the test observation must not be used for training. In other words, the dependencies between the test and training observations must reflect those between the out-of-sample observations and the sample.\n",
    "\n",
    "__How should leave-one-out cross-validation be performed in the given scenario and why?__\n",
    "\n",
    "The leave-one-out cross-validation should consider the dependencies of the pairs. If the out-of-sample is type B, the observation that share the first pair member with the test observation should not be used for training. And if the out-of-sample is type C, the observations that share the second pair member with the observation should not be used for training etc. So the leave-one-out should be performed in the way that checks if either of the pairs is in the training set. Then they should be left out of the training set. By doing it the correct way the cross-validation doesn't produce falsely high results as it doesn't learn too much of the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries you need.\n",
    "import pandas as pd\n",
    "from lifelines.utils import concordance_index\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import LeaveOneOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the utility functions you need in your analysis.\n",
    "def cindex(true, pred):\n",
    "    c_index = concordance_index(true, pred)\n",
    "    return c_index\n",
    "\n",
    "def knn_regression(X_train, y_train, X_test, k):\n",
    "    knn = KNeighborsRegressor(n_neighbors=k, metric='euclidean')\n",
    "    knn.fit(X_train, y_train)\n",
    "    prediction = knn.predict(X_test)\n",
    "    return prediction\n",
    "\n",
    "def LOOCV(X, y, pairs, k):\n",
    "    loo = LeaveOneOut()\n",
    "    y_true, y_pred = [], [] \n",
    "    for test_idx in range(len(X)):\n",
    "        test_drug, test_target = pairs.iloc[test_idx] \n",
    "        train_indices = [i for i in range(len(X))\n",
    "                         if pairs.iloc[i,0] != test_drug and pairs.iloc[i,1] != test_target]\n",
    "        X_train, X_test = X.iloc[train_indices], X.iloc[[test_idx]]\n",
    "        y_train, y_test = y.iloc[train_indices], y.iloc[[test_idx]]\n",
    "        y_pred.append(knn_regression(X_train, y_train, X_test, k)[0])\n",
    "        y_true.append(y_test.values[0])\n",
    "    return y_true, y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.759222</td>\n",
       "      <td>0.709585</td>\n",
       "      <td>0.253151</td>\n",
       "      <td>0.421082</td>\n",
       "      <td>0.727780</td>\n",
       "      <td>0.404487</td>\n",
       "      <td>0.709027</td>\n",
       "      <td>0.242963</td>\n",
       "      <td>0.407292</td>\n",
       "      <td>0.379971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838616</td>\n",
       "      <td>0.165050</td>\n",
       "      <td>0.515334</td>\n",
       "      <td>0.332678</td>\n",
       "      <td>0.577533</td>\n",
       "      <td>0.678125</td>\n",
       "      <td>0.463608</td>\n",
       "      <td>0.538938</td>\n",
       "      <td>0.460883</td>\n",
       "      <td>0.345251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.034584</td>\n",
       "      <td>0.304720</td>\n",
       "      <td>0.688257</td>\n",
       "      <td>0.296396</td>\n",
       "      <td>0.151878</td>\n",
       "      <td>0.830755</td>\n",
       "      <td>0.270656</td>\n",
       "      <td>0.705392</td>\n",
       "      <td>0.186120</td>\n",
       "      <td>0.085594</td>\n",
       "      <td>...</td>\n",
       "      <td>0.472762</td>\n",
       "      <td>0.730013</td>\n",
       "      <td>0.639373</td>\n",
       "      <td>0.445218</td>\n",
       "      <td>0.455680</td>\n",
       "      <td>0.090737</td>\n",
       "      <td>0.308432</td>\n",
       "      <td>0.079023</td>\n",
       "      <td>0.603089</td>\n",
       "      <td>0.197008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.737867</td>\n",
       "      <td>0.236079</td>\n",
       "      <td>0.905987</td>\n",
       "      <td>0.163612</td>\n",
       "      <td>0.801455</td>\n",
       "      <td>0.789823</td>\n",
       "      <td>0.393999</td>\n",
       "      <td>0.522067</td>\n",
       "      <td>0.411352</td>\n",
       "      <td>0.781861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.595468</td>\n",
       "      <td>0.582292</td>\n",
       "      <td>0.836193</td>\n",
       "      <td>0.281514</td>\n",
       "      <td>0.791790</td>\n",
       "      <td>0.081695</td>\n",
       "      <td>0.583450</td>\n",
       "      <td>0.422539</td>\n",
       "      <td>0.076437</td>\n",
       "      <td>0.299662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.406913</td>\n",
       "      <td>0.607740</td>\n",
       "      <td>0.235365</td>\n",
       "      <td>0.888679</td>\n",
       "      <td>0.150347</td>\n",
       "      <td>0.598991</td>\n",
       "      <td>0.130108</td>\n",
       "      <td>0.465818</td>\n",
       "      <td>0.799953</td>\n",
       "      <td>0.906878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453880</td>\n",
       "      <td>0.311799</td>\n",
       "      <td>0.534668</td>\n",
       "      <td>0.563793</td>\n",
       "      <td>0.727767</td>\n",
       "      <td>0.172686</td>\n",
       "      <td>0.908368</td>\n",
       "      <td>0.786892</td>\n",
       "      <td>0.790459</td>\n",
       "      <td>0.666388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.697707</td>\n",
       "      <td>0.432565</td>\n",
       "      <td>0.650329</td>\n",
       "      <td>0.886065</td>\n",
       "      <td>0.328660</td>\n",
       "      <td>0.576926</td>\n",
       "      <td>0.523100</td>\n",
       "      <td>0.080463</td>\n",
       "      <td>0.131349</td>\n",
       "      <td>0.913496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583892</td>\n",
       "      <td>0.444141</td>\n",
       "      <td>0.249423</td>\n",
       "      <td>0.110690</td>\n",
       "      <td>0.420770</td>\n",
       "      <td>0.250148</td>\n",
       "      <td>0.196350</td>\n",
       "      <td>0.427255</td>\n",
       "      <td>0.166715</td>\n",
       "      <td>0.919720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.496498</td>\n",
       "      <td>0.454389</td>\n",
       "      <td>0.353502</td>\n",
       "      <td>0.696922</td>\n",
       "      <td>0.876419</td>\n",
       "      <td>0.379429</td>\n",
       "      <td>0.733514</td>\n",
       "      <td>0.839360</td>\n",
       "      <td>0.212366</td>\n",
       "      <td>0.530528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054742</td>\n",
       "      <td>0.212866</td>\n",
       "      <td>0.657035</td>\n",
       "      <td>0.483128</td>\n",
       "      <td>0.807080</td>\n",
       "      <td>0.566457</td>\n",
       "      <td>0.379042</td>\n",
       "      <td>0.566572</td>\n",
       "      <td>0.512170</td>\n",
       "      <td>0.421929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.188616</td>\n",
       "      <td>0.554824</td>\n",
       "      <td>0.609247</td>\n",
       "      <td>0.371482</td>\n",
       "      <td>0.588356</td>\n",
       "      <td>0.667919</td>\n",
       "      <td>0.297278</td>\n",
       "      <td>0.269298</td>\n",
       "      <td>0.856952</td>\n",
       "      <td>0.697523</td>\n",
       "      <td>...</td>\n",
       "      <td>0.549288</td>\n",
       "      <td>0.843150</td>\n",
       "      <td>0.739872</td>\n",
       "      <td>0.481870</td>\n",
       "      <td>0.359285</td>\n",
       "      <td>0.593446</td>\n",
       "      <td>0.788714</td>\n",
       "      <td>0.142521</td>\n",
       "      <td>0.819989</td>\n",
       "      <td>0.637718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.095054</td>\n",
       "      <td>0.452918</td>\n",
       "      <td>0.942931</td>\n",
       "      <td>0.576332</td>\n",
       "      <td>0.411317</td>\n",
       "      <td>0.561792</td>\n",
       "      <td>0.837251</td>\n",
       "      <td>0.806083</td>\n",
       "      <td>0.581221</td>\n",
       "      <td>0.829656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.900376</td>\n",
       "      <td>0.378294</td>\n",
       "      <td>0.360243</td>\n",
       "      <td>0.259965</td>\n",
       "      <td>0.716623</td>\n",
       "      <td>0.817797</td>\n",
       "      <td>0.792314</td>\n",
       "      <td>0.736228</td>\n",
       "      <td>0.233031</td>\n",
       "      <td>0.597934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.166109</td>\n",
       "      <td>0.471535</td>\n",
       "      <td>0.509825</td>\n",
       "      <td>0.415422</td>\n",
       "      <td>0.620681</td>\n",
       "      <td>0.786712</td>\n",
       "      <td>0.150722</td>\n",
       "      <td>0.282159</td>\n",
       "      <td>0.809963</td>\n",
       "      <td>0.809090</td>\n",
       "      <td>...</td>\n",
       "      <td>0.587865</td>\n",
       "      <td>0.955456</td>\n",
       "      <td>0.714566</td>\n",
       "      <td>0.520387</td>\n",
       "      <td>0.397173</td>\n",
       "      <td>0.575056</td>\n",
       "      <td>0.822135</td>\n",
       "      <td>0.096667</td>\n",
       "      <td>0.946201</td>\n",
       "      <td>0.604271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.817295</td>\n",
       "      <td>0.326707</td>\n",
       "      <td>0.500573</td>\n",
       "      <td>0.022480</td>\n",
       "      <td>0.266418</td>\n",
       "      <td>0.463136</td>\n",
       "      <td>0.720725</td>\n",
       "      <td>0.900571</td>\n",
       "      <td>0.178126</td>\n",
       "      <td>0.405540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.711878</td>\n",
       "      <td>0.362695</td>\n",
       "      <td>0.555318</td>\n",
       "      <td>0.145665</td>\n",
       "      <td>0.309317</td>\n",
       "      <td>0.884572</td>\n",
       "      <td>0.332518</td>\n",
       "      <td>0.944396</td>\n",
       "      <td>0.070304</td>\n",
       "      <td>0.052850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0    0.759222  0.709585  0.253151  0.421082  0.727780  0.404487  0.709027   \n",
       "1    0.034584  0.304720  0.688257  0.296396  0.151878  0.830755  0.270656   \n",
       "2    0.737867  0.236079  0.905987  0.163612  0.801455  0.789823  0.393999   \n",
       "3    0.406913  0.607740  0.235365  0.888679  0.150347  0.598991  0.130108   \n",
       "4    0.697707  0.432565  0.650329  0.886065  0.328660  0.576926  0.523100   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "395  0.496498  0.454389  0.353502  0.696922  0.876419  0.379429  0.733514   \n",
       "396  0.188616  0.554824  0.609247  0.371482  0.588356  0.667919  0.297278   \n",
       "397  0.095054  0.452918  0.942931  0.576332  0.411317  0.561792  0.837251   \n",
       "398  0.166109  0.471535  0.509825  0.415422  0.620681  0.786712  0.150722   \n",
       "399  0.817295  0.326707  0.500573  0.022480  0.266418  0.463136  0.720725   \n",
       "\n",
       "           7         8         9   ...        57        58        59  \\\n",
       "0    0.242963  0.407292  0.379971  ...  0.838616  0.165050  0.515334   \n",
       "1    0.705392  0.186120  0.085594  ...  0.472762  0.730013  0.639373   \n",
       "2    0.522067  0.411352  0.781861  ...  0.595468  0.582292  0.836193   \n",
       "3    0.465818  0.799953  0.906878  ...  0.453880  0.311799  0.534668   \n",
       "4    0.080463  0.131349  0.913496  ...  0.583892  0.444141  0.249423   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "395  0.839360  0.212366  0.530528  ...  0.054742  0.212866  0.657035   \n",
       "396  0.269298  0.856952  0.697523  ...  0.549288  0.843150  0.739872   \n",
       "397  0.806083  0.581221  0.829656  ...  0.900376  0.378294  0.360243   \n",
       "398  0.282159  0.809963  0.809090  ...  0.587865  0.955456  0.714566   \n",
       "399  0.900571  0.178126  0.405540  ...  0.711878  0.362695  0.555318   \n",
       "\n",
       "           60        61        62        63        64        65        66  \n",
       "0    0.332678  0.577533  0.678125  0.463608  0.538938  0.460883  0.345251  \n",
       "1    0.445218  0.455680  0.090737  0.308432  0.079023  0.603089  0.197008  \n",
       "2    0.281514  0.791790  0.081695  0.583450  0.422539  0.076437  0.299662  \n",
       "3    0.563793  0.727767  0.172686  0.908368  0.786892  0.790459  0.666388  \n",
       "4    0.110690  0.420770  0.250148  0.196350  0.427255  0.166715  0.919720  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "395  0.483128  0.807080  0.566457  0.379042  0.566572  0.512170  0.421929  \n",
       "396  0.481870  0.359285  0.593446  0.788714  0.142521  0.819989  0.637718  \n",
       "397  0.259965  0.716623  0.817797  0.792314  0.736228  0.233031  0.597934  \n",
       "398  0.520387  0.397173  0.575056  0.822135  0.096667  0.946201  0.604271  \n",
       "399  0.145665  0.309317  0.884572  0.332518  0.944396  0.070304  0.052850  \n",
       "\n",
       "[400 rows x 67 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read the data files (input.data, output.data, pairs.data).\n",
    "input_data = pd.read_csv('input.data', delimiter=\" \", header=None)\n",
    "output_data = pd.read_csv('output.data', delimiter=\" \", header=None)\n",
    "pairs_data = pd.read_csv('pairs.data', delimiter=\" \", header=None)\n",
    "display(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement and run cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimate of how well the model worked: 0.522\n"
     ]
    }
   ],
   "source": [
    "# Implement and run the requested cross-validation. Report and interpret its results.\n",
    "k = 10\n",
    "y_true, y_pred = LOOCV(input_data, output_data, pairs_data, k)\n",
    "result = cindex(y_true, y_pred)\n",
    "print(f\"The estimate of how well the model worked: {result:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Dear Bio Scientist,_\n",
    "\n",
    "0.5 is the worst result we can get from cross-validation. Based on the result 0.522 the model doesn't work well for this case. I would say it would be waste of your resources if you were to use the model any further. The models results are only slightly better than a guess. It is 50% of the time correct and the other times wrong. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
